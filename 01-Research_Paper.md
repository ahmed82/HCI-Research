# Research Paper Summary 1
## Heuristic Evaluation of Conversational Agents
Research in Human Computer Interaction includes the development and assessment of new technologies and innovations in how people and technology interact and collaborate. As an introduction to HCI research, you will read and summarize a number of published research papers.

Refer to the [HCI Research Learning Guide](https://github.com/ahmed82/HCI-Research/blob/main/README.md) for guidance on how to read and how to summarize research paper.

For this assignment, read the following research paper, and submit a summary according to the structure below.

## Research Paper

* Heuristic Evaluation of Conversational Agents Download Heuristic Evaluation of Conversational Agents
    * For reference, this article is available from the Association for Computing Machinery (ACM) Digital Library: [ACM DL Entry for Heuristic Evaluation of Conversational Agents](https://dl.acm.org/doi/abs/10.1145/3411764.3445312?casa_token=pJC93dLZf2UAAAAA:qCtUa5ZQ6SNCqQRhXSKKnvZKIIQgF3r2rfgV1Cld3XMvBj08fmL8elJ2trHSh-RoFEcSdE9AEOwu)

## Paper Summary

* Read the assigned research paper.
* You are reading for more general, high-level understanding.
* Some of the details (on the methods or experimentation in particular) may be more in-depth than needed for a general, high-level understanding of the work.  You should still read through, but don't worry if some of the elements are not easy to understand.  Take a step back and think about what they are trying to accomplish, rather than the fine-grained steps or analysis.
* Take notes as you read.
* Summarize the paper by answering the following questions:
1. Main Issue: What is the main issue or problem being addressed?  Why should people care?
2. Approach: What method or approach does the paper propose as a way to help address the main issue or problem?
3. Related Work / Context: Does the paper build on previously reported research, and is that clearly identified? 
4. Evaluation / Analysis: Does the paper conduct a study or experiment to test whether the proposed method or approach? 
5. Lessons Learned: Based on the approach / study / experiment, what are the main lessons learned, takeaways, or outcomes from the paper?

-----
# Heuristic Evaluation of Conversational Agents Summery
**Main Issue:** The conversational models become one of the most widely used groups of interaction types in the website that offers customer support in official methods such as chatbot window to establish a conversation with the user answering questions and provide a guidance, and have been extensively used for text and voice input as I mentioned in chatbots and Intelligent Personal Assistants, the problem is the existing design evaluation models, does not meet all of the current requirement to build good conversational system, as the designers depends on a list of usability heuristics, that could use for evaluating the design of the conversational agent. Most of the systems are built based on Nielsen’s Heuristic and others include reference and contribute of study that prove that this list is outdated.

**Approach:** The authors propose a set of heuristics for conversational agents based on expert feedback on four round faces that each face includes an enhanced set for fullfill the model design needs. The work started by adapting a set of heuristics from Nielsen’s heuristics and building on top of it, The validation of the heuristics by establishing two rounds of evaluations administered by the participants on two conversational agents, in order to cover the most recent technology of conversation model which is one for chatbot and one for the voice-based personal assistant. In the last phase of the heuristics set tuning in the research paper contribution the authors validated the new heuristics list by comparing the errors hundling of the design agnesit Nielsen’s heuristics. Publishing the final set of 11 heuristics, performing with better efficiency than Nielsen’s heuristics evaluate both interfaces text and voice. Prosperous identify design issues appertained
to assist and guide, dialogue content, interaction design, human-like characteristics, and data privacy when design new conversation agent.


**Related Work / Context:** Jakob Nielsen’s 10 usability heuristics adapted tobuilt the list of evaluation the design of the conversational agents, is the related work to this research study. Nielsen’s Heuristics are a well-established set of guidelines that tend to result in interface design when they are incorporated into the design process. The most relative work that drives the research is by Nielsen and Molich in the 1990s, who research the usability problems of a telephone index system and addressed nine heuristics. As sure as outlined but it is still widely used today after Nielsen Jakob In 1994 updated the set of the heuristics. However, the research paper proposed the comparative results of Nielsen’s heuristics and the author's heuristic proving the performance of evaluating using the new system also. 

**Evaluation / Analysis:** The validation of the heuristics through two evaluations was conducted, the test was on two conversational agents, one chatbot, and one voice-based personal assistant. However, the evaluation was of two types, the first in-person study, and the second In the online study, the in-person evaluation establish by asking the tested or the evaluators to use the Amazon Echo in order to evaluate a voice assistant the team have to use an Alexa skill on the Amazon website that connects to a Slack workspace. 
Another hand In the online study, a chatbot interface text-based was developed to target patients in the emergency room department in a hospital as people participated in a survey answering a variety of questions.

**Lessons Learned:** as the need of enhancing the evaluating system to serve the new technology, since the traditional way of evaluating the system does not satisfy the business need, however considering Nielsen’s heuristics as a foundation set could help as a starting stage to be used to evaluate the system and customize the list of the heuristics for the best result based on the new system and the business needs. Also, the design of an evaluation system can be enhanced to support different platforms or systems as we see in this paper proposed a new set of heuristics in four faces to evaluate both interfaces text, and voice. Successfully identify issues related to assist and guide, dialogue content, interaction design, human-like characteristics, and data privacy. The authors showed that conversational agent heuristics are more effective than Nielsen's in identifying usability problems. It could be necessary to assess both user interactions and the dialogue in order to provide a positive user experience. As we should consider the limitation as part of the outcome of this paper which indicates that the small number of participants and their level of heuristic evaluation expertise is another limitation to the results being accurate.
