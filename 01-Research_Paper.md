# Research Paper Summary 1
## Heuristic Evaluation of Conversational Agents
Research in Human Computer Interaction includes the development and assessment of new technologies and innovations in how people and technology interact and collaborate. As an introduction to HCI research, you will read and summarize a number of published research papers.

Refer to the [HCI Research Learning Guide](https://github.com/ahmed82/HCI-Research/blob/main/README.md) for guidance on how to read and how to summarize research paper.

For this assignment, read the following research paper, and submit a summary according to the structure below.

## Research Paper

* Heuristic Evaluation of Conversational Agents Download Heuristic Evaluation of Conversational Agents
    * For reference, this article is available from the Association for Computing Machinery (ACM) Digital Library: [ACM DL Entry for Heuristic Evaluation of Conversational Agents](https://dl.acm.org/doi/abs/10.1145/3411764.3445312?casa_token=pJC93dLZf2UAAAAA:qCtUa5ZQ6SNCqQRhXSKKnvZKIIQgF3r2rfgV1Cld3XMvBj08fmL8elJ2trHSh-RoFEcSdE9AEOwu)

## Paper Summary

* Read the assigned research paper.
* You are reading for more general, high-level understanding.
* Some of the details (on the methods or experimentation in particular) may be more in-depth than needed for a general, high-level understanding of the work.  You should still read through, but don't worry if some of the elements are not easy to understand.  Take a step back and think about what they are trying to accomplish, rather than the fine-grained steps or analysis.
* Take notes as you read.
* Summarize the paper by answering the following questions:
1. Main Issue: What is the main issue or problem being addressed?  Why should people care?
2. Approach: What method or approach does the paper propose as a way to help address the main issue or problem?
3. Related Work / Context: Does the paper build on previously reported research, and is that clearly identified? 
4. Evaluation / Analysis: Does the paper conduct a study or experiment to test whether the proposed method or approach? 
5. Lessons Learned: Based on the approach / study / experiment, what are the main lessons learned, takeaways, or outcomes from the paper?

-----
# Heuristic Evaluation of Conversational Agents Summary
**Main Issue:** The conversational models have become one of the most widely used groups of interaction types on the website that offers customer support in official methods. Such as a chatbot window to establish a conversation with the user, answer questions, and provide guidance, and have been extensively used for text and voice input. The problem is that the existing design evaluation models do not meet all of the current requirements to build a sound conversational system. The designers depend on a list of usability heuristics that could be used to evaluate the conversational agent's design. as I mentioned in chatbots and Intelligent Personal Assistants. Most systems are built based on Nielsen's Heuristic; others include references and contributions of studies that prove this list is outdated.

**Approach:** The authors propose a set of heuristics for conversational agents based on expert feedback on four round faces. Each face includes an enhanced set to fulfill the model design needs. The work started by adapting a set of heuristics from Nielsen's heuristics and building on top of it. The validation of the heuristics by establishing two rounds of evaluations administered by the participants on two conversational agents in order to cover the most recent technology of the conversation model, which is one for the chatbot and one for the voice-based personal assistant. In the last phase of the heuristics set tuning in the research paper contribution, the authors validated the new heuristics list by comparing the errors in handling the design against Nielsen's heuristics. Publishing the final set of 11 heuristics, performing with better efficiency than Nielsen's heuristics, evaluates both interfaces text and voice. Prosperous identify design issues appertained
to assist and guide dialogue content, interaction design, human-like characteristics, and data privacy when designing new conversation agents.


**Related Work / Context:** Jakob Nielsen's 10 usability heuristics adapted to build the list of evaluations of the design of conversational agent design is the related work to this research study. Nielsen's Heuristics are a well-established set of guidelines that tend to result in interface design when incorporated into the design process. The most recent work that drives the research is by Nielsen and Molich in the 1990s, who researched the usability problems of a telephone index system and addressed nine heuristics. As sure as outlined but it is still widely used today after Nielsen Jakob, In 1994, updated the heuristics. However, the research paper also proposed the comparative results of Nielsen's heuristics and the author's heuristic, proving the performance of evaluating using the new system. 

**Evaluation / Analysis:** The heuristics were validated through two evaluations. The test was on two conversational agents, one chatbot, and one voice-based personal assistant. However, the evaluation was of two types, the first in-person study and the second. In the online study, the in-person evaluation was established by asking the tested or the evaluators to use the Amazon Echo to evaluate a voice assistant. The team has to use an Alexa skill on the Amazon website that connects to a Slack workspace. 
Another hand In the online study, a chatbot interface text-based was developed to target patients in the emergency room department in a hospital as people participated in a survey answering various questions.

**Lessons Learned:** the need to enhance the evaluating system to serve the new technology since the traditional way of evaluating the system does not satisfy the business need. However, considering Nielsen's heuristics as a foundation set could help as a starting stage to evaluate the system and customize the list of the heuristics for the best result based on the new system and the business needs. Also, the design of an evaluation system can be enhanced to support different platforms or systems, as we see in this paper, proposed a new set of heuristics in four faces to evaluate both interfaces, text, and voice. Successfully identify issues related to assisting and guiding dialogue content, interaction design, human-like characteristics, and data privacy. The authors showed that conversational agent heuristics are more effective than Nielsen's in identifying usability problems. It could be necessary to assess user interactions and the dialogue in order to provide a positive user experience, as we should consider the limitation as part of the outcome of this paper, which indicates that the small number of participants and their level of heuristic evaluation expertise is another limitation to the results being accurate.
